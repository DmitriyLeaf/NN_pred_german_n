{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import Sequential\n",
    "import numpy as np\n",
    "import codecs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "import time\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_LEN = 25\n",
    "MAX_LEN_CODE = 123.0\n",
    "END_LEN = 20\n",
    "F_NAME = \"data_sets/dict.cc_nouns_with_gender.txt\"\n",
    "FILE_TEST_NAME = \"data_sets/deutsch_test_asc_1.txt\"\n",
    "DROP_OUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file_name, MAX_LEN_CODE, END_LEN):\n",
    "    training_data_file = open(file_name, 'r')\n",
    "    training_data_list = training_data_file.readlines()\n",
    "    training_data_file.close()\n",
    "\n",
    "    training_data_list = training_data_list[1:]\n",
    "    print(training_data_list[:10])\n",
    "    np.random.shuffle(training_data_list)\n",
    "    print(training_data_list[:10])\n",
    "\n",
    "    f_inputs = [[[0] for i in range(0, END_LEN)]]\n",
    "    targets = []\n",
    "    f_inputs = np.asfarray(f_inputs)\n",
    "\n",
    "    for record in training_data_list:\n",
    "        all_values = record.split(' ')\n",
    "        all_values = [word.replace(\"\\n\", \"\") for word in all_values]\n",
    "        i = [0]\n",
    "        for letter in all_values[1]:\n",
    "            i = np.vstack((i, np.asfarray([ord(letter.lower())/MAX_LEN_CODE])))\n",
    "            pass\n",
    "        inputs = i\n",
    "        if(len(inputs) > END_LEN):\n",
    "            inputs = inputs[len(inputs)-END_LEN:]\n",
    "        elif(len(inputs) < END_LEN):\n",
    "            begin = np.zeros((END_LEN - len(inputs)), dtype=np.float)\n",
    "            for b in begin:\n",
    "                inputs = np.vstack((b, inputs))\n",
    "                pass\n",
    "        f_inputs = np.vstack((f_inputs, [inputs]))\n",
    "\n",
    "        targets.append(all_values[0])\n",
    "\n",
    "    f_inputs = np.delete(f_inputs, 0, 0)\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(targets)\n",
    "    new_targets = encoder.transform(targets)\n",
    "    f_targets = np_utils.to_categorical(new_targets)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return f_inputs, f_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['die AAA-Einstufung {f}\\n', 'die Aach {f}\\n', 'das Aach {n}\\n', 'das Aachen {n}\\n', 'der Aachener {m}\\n', 'die Aachenerin {f}\\n', 'die Aachenfahrt {f}\\n', 'die AA-Formula {f}\\n', 'der Aagaard-Gletscher {m}\\n', 'das Aagenaes-Syndrom {n}\\n']\n",
      "['die Nassalarmventilstation {f}\\n', 'die Vers_hnung {f}\\n', 'der Anzac {m}\\n', 'die Eigent]mergemeinschaft {f}\\n', 'der Fertigungsbereich {m}\\n', 'die Abszissenachse {f}\\n', 'die Kongestion {f}\\n', 'die Sondertilgung {f}\\n', 'der Fahlstirnsericornis {m}\\n', 'der Fahrradreifengummi {m}\\n']\n"
     ]
    }
   ],
   "source": [
    "X, Y = readFile(F_NAME, MAX_LEN_CODE, END_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 280371 samples, validate on 93457 samples\n",
      "Epoch 1/100\n",
      "280371/280371 [==============================] - 391s 1ms/step - loss: 1.0451 - acc: 0.4563 - val_loss: 1.0022 - val_acc: 0.5298\n",
      "Epoch 2/100\n",
      "280371/280371 [==============================] - 382s 1ms/step - loss: 0.8992 - acc: 0.5815 - val_loss: 0.8348 - val_acc: 0.6265\n",
      "Epoch 3/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.8413 - acc: 0.6174 - val_loss: 0.8082 - val_acc: 0.6358\n",
      "Epoch 4/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.8002 - acc: 0.6402 - val_loss: 0.7758 - val_acc: 0.6620\n",
      "Epoch 5/100\n",
      "280371/280371 [==============================] - 299s 1ms/step - loss: 0.7622 - acc: 0.6641 - val_loss: 0.7268 - val_acc: 0.6889\n",
      "Epoch 6/100\n",
      "280371/280371 [==============================] - 299s 1ms/step - loss: 0.7304 - acc: 0.6816 - val_loss: 0.6876 - val_acc: 0.7079\n",
      "Epoch 7/100\n",
      "280371/280371 [==============================] - 366s 1ms/step - loss: 0.7031 - acc: 0.6970 - val_loss: 0.6598 - val_acc: 0.7225\n",
      "Epoch 8/100\n",
      "280371/280371 [==============================] - 449s 2ms/step - loss: 0.6822 - acc: 0.7068 - val_loss: 0.6390 - val_acc: 0.7281\n",
      "Epoch 9/100\n",
      "280371/280371 [==============================] - 428s 2ms/step - loss: 0.6641 - acc: 0.7144 - val_loss: 0.6120 - val_acc: 0.7402\n",
      "Epoch 10/100\n",
      "280371/280371 [==============================] - 593s 2ms/step - loss: 0.6472 - acc: 0.7235 - val_loss: 0.6090 - val_acc: 0.7438\n",
      "Epoch 11/100\n",
      "280371/280371 [==============================] - 483s 2ms/step - loss: 0.6331 - acc: 0.7293 - val_loss: 0.5896 - val_acc: 0.7515\n",
      "Epoch 12/100\n",
      "280371/280371 [==============================] - 539s 2ms/step - loss: 0.6175 - acc: 0.7373 - val_loss: 0.5803 - val_acc: 0.7570\n",
      "Epoch 13/100\n",
      "280371/280371 [==============================] - 466s 2ms/step - loss: 0.6049 - acc: 0.7447 - val_loss: 0.5673 - val_acc: 0.7656\n",
      "Epoch 14/100\n",
      "280371/280371 [==============================] - 467s 2ms/step - loss: 0.5930 - acc: 0.7507 - val_loss: 0.5562 - val_acc: 0.7670\n",
      "Epoch 15/100\n",
      "280371/280371 [==============================] - 391s 1ms/step - loss: 0.5824 - acc: 0.7570 - val_loss: 0.5306 - val_acc: 0.7822\n",
      "Epoch 16/100\n",
      "280371/280371 [==============================] - 395s 1ms/step - loss: 0.5693 - acc: 0.7632 - val_loss: 0.5289 - val_acc: 0.7847\n",
      "Epoch 17/100\n",
      "280371/280371 [==============================] - 478s 2ms/step - loss: 0.5593 - acc: 0.7685 - val_loss: 0.5174 - val_acc: 0.7891\n",
      "Epoch 18/100\n",
      "280371/280371 [==============================] - 463s 2ms/step - loss: 0.5496 - acc: 0.7732 - val_loss: 0.5042 - val_acc: 0.7966\n",
      "Epoch 19/100\n",
      "280371/280371 [==============================] - 483s 2ms/step - loss: 0.5392 - acc: 0.7787 - val_loss: 0.4848 - val_acc: 0.8061\n",
      "Epoch 20/100\n",
      "280371/280371 [==============================] - 437s 2ms/step - loss: 0.5306 - acc: 0.7833 - val_loss: 0.4908 - val_acc: 0.8016\n",
      "Epoch 21/100\n",
      "280371/280371 [==============================] - 397s 1ms/step - loss: 0.5219 - acc: 0.7863 - val_loss: 0.4784 - val_acc: 0.8076\n",
      "Epoch 22/100\n",
      "280371/280371 [==============================] - 399s 1ms/step - loss: 0.5146 - acc: 0.7906 - val_loss: 0.4780 - val_acc: 0.8082\n",
      "Epoch 23/100\n",
      "280371/280371 [==============================] - 399s 1ms/step - loss: 0.5079 - acc: 0.7922 - val_loss: 0.4578 - val_acc: 0.8173\n",
      "Epoch 24/100\n",
      "280371/280371 [==============================] - 334s 1ms/step - loss: 0.5004 - acc: 0.7968 - val_loss: 0.4560 - val_acc: 0.8201\n",
      "Epoch 25/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4961 - acc: 0.7984 - val_loss: 0.4540 - val_acc: 0.8186\n",
      "Epoch 26/100\n",
      "280371/280371 [==============================] - 293s 1ms/step - loss: 0.4896 - acc: 0.8020 - val_loss: 0.4474 - val_acc: 0.8221\n",
      "Epoch 27/100\n",
      "280371/280371 [==============================] - 292s 1ms/step - loss: 0.4845 - acc: 0.8043 - val_loss: 0.4491 - val_acc: 0.8198\n",
      "Epoch 28/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4790 - acc: 0.8073 - val_loss: 0.4244 - val_acc: 0.8306\n",
      "Epoch 29/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4726 - acc: 0.8096 - val_loss: 0.4280 - val_acc: 0.8295\n",
      "Epoch 30/100\n",
      "280371/280371 [==============================] - 314s 1ms/step - loss: 0.4674 - acc: 0.8125 - val_loss: 0.4175 - val_acc: 0.8376\n",
      "Epoch 31/100\n",
      "280371/280371 [==============================] - 347s 1ms/step - loss: 0.4632 - acc: 0.8144 - val_loss: 0.4154 - val_acc: 0.8388\n",
      "Epoch 32/100\n",
      "280371/280371 [==============================] - 302s 1ms/step - loss: 0.4574 - acc: 0.8175 - val_loss: 0.4016 - val_acc: 0.8416\n",
      "Epoch 33/100\n",
      "280371/280371 [==============================] - 299s 1ms/step - loss: 0.4546 - acc: 0.8187 - val_loss: 0.4046 - val_acc: 0.8426\n",
      "Epoch 34/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4493 - acc: 0.8209 - val_loss: 0.4392 - val_acc: 0.8263\n",
      "Epoch 35/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4463 - acc: 0.8218 - val_loss: 0.3994 - val_acc: 0.8436\n",
      "Epoch 36/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4427 - acc: 0.8233 - val_loss: 0.3990 - val_acc: 0.8462\n",
      "Epoch 37/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4379 - acc: 0.8267 - val_loss: 0.4112 - val_acc: 0.8370\n",
      "Epoch 38/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4342 - acc: 0.8277 - val_loss: 0.3943 - val_acc: 0.8454\n",
      "Epoch 39/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.4311 - acc: 0.8286 - val_loss: 0.3845 - val_acc: 0.8494\n",
      "Epoch 40/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4275 - acc: 0.8318 - val_loss: 0.3809 - val_acc: 0.8521\n",
      "Epoch 41/100\n",
      "280371/280371 [==============================] - 296s 1ms/step - loss: 0.4233 - acc: 0.8331 - val_loss: 0.3864 - val_acc: 0.8504\n",
      "Epoch 42/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.4214 - acc: 0.8336 - val_loss: 0.3742 - val_acc: 0.8572\n",
      "Epoch 43/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4179 - acc: 0.8354 - val_loss: 0.3793 - val_acc: 0.8526\n",
      "Epoch 44/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4136 - acc: 0.8379 - val_loss: 0.3752 - val_acc: 0.8563\n",
      "Epoch 45/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.4105 - acc: 0.8393 - val_loss: 0.3659 - val_acc: 0.8589\n",
      "Epoch 46/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4078 - acc: 0.8400 - val_loss: 0.3644 - val_acc: 0.8601\n",
      "Epoch 47/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4035 - acc: 0.8428 - val_loss: 0.3638 - val_acc: 0.8604\n",
      "Epoch 48/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.4018 - acc: 0.8428 - val_loss: 0.3617 - val_acc: 0.8613\n",
      "Epoch 49/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3993 - acc: 0.8444 - val_loss: 0.3597 - val_acc: 0.8623\n",
      "Epoch 50/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.3960 - acc: 0.8455 - val_loss: 0.3500 - val_acc: 0.8653\n",
      "Epoch 51/100\n",
      "280371/280371 [==============================] - 297s 1ms/step - loss: 0.3929 - acc: 0.8466 - val_loss: 0.3581 - val_acc: 0.8626\n",
      "Epoch 52/100\n",
      "280371/280371 [==============================] - 299s 1ms/step - loss: 0.3893 - acc: 0.8484 - val_loss: 0.3477 - val_acc: 0.8664\n",
      "Epoch 53/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3876 - acc: 0.8492 - val_loss: 0.3457 - val_acc: 0.8669\n",
      "Epoch 54/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3853 - acc: 0.8500 - val_loss: 0.3412 - val_acc: 0.8700\n",
      "Epoch 55/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3823 - acc: 0.8521 - val_loss: 0.3487 - val_acc: 0.8695\n",
      "Epoch 56/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3801 - acc: 0.8524 - val_loss: 0.3365 - val_acc: 0.8732\n",
      "Epoch 57/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3770 - acc: 0.8539 - val_loss: 0.3365 - val_acc: 0.8728\n",
      "Epoch 58/100\n",
      "280371/280371 [==============================] - 298s 1ms/step - loss: 0.3736 - acc: 0.8554 - val_loss: 0.3395 - val_acc: 0.8724\n",
      "Epoch 59/100\n",
      "280371/280371 [==============================] - 302s 1ms/step - loss: 0.3725 - acc: 0.8560 - val_loss: 0.3411 - val_acc: 0.8713\n",
      "Epoch 60/100\n",
      "280371/280371 [==============================] - 166s 592us/step - loss: 0.3698 - acc: 0.8576 - val_loss: 0.3398 - val_acc: 0.8708\n",
      "Epoch 61/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3688 - acc: 0.8578 - val_loss: 0.3300 - val_acc: 0.8763\n",
      "Epoch 62/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3658 - acc: 0.8591 - val_loss: 0.3305 - val_acc: 0.8773\n",
      "Epoch 63/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3652 - acc: 0.8595 - val_loss: 0.3265 - val_acc: 0.8787\n",
      "Epoch 64/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3618 - acc: 0.8605 - val_loss: 0.3283 - val_acc: 0.8769\n",
      "Epoch 65/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3592 - acc: 0.8618 - val_loss: 0.3359 - val_acc: 0.8722\n",
      "Epoch 66/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3583 - acc: 0.8620 - val_loss: 0.3303 - val_acc: 0.8758\n",
      "Epoch 67/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3563 - acc: 0.8629 - val_loss: 0.3186 - val_acc: 0.8793\n",
      "Epoch 68/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3543 - acc: 0.8645 - val_loss: 0.3158 - val_acc: 0.8831\n",
      "Epoch 69/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3515 - acc: 0.8653 - val_loss: 0.3265 - val_acc: 0.8771\n",
      "Epoch 70/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3513 - acc: 0.8651 - val_loss: 0.3197 - val_acc: 0.8811\n",
      "Epoch 71/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3486 - acc: 0.8670 - val_loss: 0.3194 - val_acc: 0.8801\n",
      "Epoch 72/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3461 - acc: 0.8677 - val_loss: 0.3147 - val_acc: 0.8827\n",
      "Epoch 73/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3448 - acc: 0.8686 - val_loss: 0.3151 - val_acc: 0.8822\n",
      "Epoch 74/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3439 - acc: 0.8687 - val_loss: 0.3139 - val_acc: 0.8832\n",
      "Epoch 75/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3430 - acc: 0.8689 - val_loss: 0.3145 - val_acc: 0.8837\n",
      "Epoch 76/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3410 - acc: 0.8697 - val_loss: 0.3010 - val_acc: 0.8892\n",
      "Epoch 77/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3398 - acc: 0.8700 - val_loss: 0.3089 - val_acc: 0.8860\n",
      "Epoch 78/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3373 - acc: 0.8714 - val_loss: 0.3191 - val_acc: 0.8826\n",
      "Epoch 79/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3352 - acc: 0.8723 - val_loss: 0.3132 - val_acc: 0.8832\n",
      "Epoch 80/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3346 - acc: 0.8729 - val_loss: 0.3194 - val_acc: 0.8823\n",
      "Epoch 81/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3336 - acc: 0.8734 - val_loss: 0.3034 - val_acc: 0.8891\n",
      "Epoch 82/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3320 - acc: 0.8738 - val_loss: 0.3067 - val_acc: 0.8857\n",
      "Epoch 83/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3301 - acc: 0.8747 - val_loss: 0.3007 - val_acc: 0.8879\n",
      "Epoch 84/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3292 - acc: 0.8749 - val_loss: 0.2976 - val_acc: 0.8909\n",
      "Epoch 85/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3281 - acc: 0.8755 - val_loss: 0.2957 - val_acc: 0.8903\n",
      "Epoch 86/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3267 - acc: 0.8763 - val_loss: 0.3108 - val_acc: 0.8851\n",
      "Epoch 87/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3253 - acc: 0.8769 - val_loss: 0.2896 - val_acc: 0.8930\n",
      "Epoch 88/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3233 - acc: 0.8778 - val_loss: 0.2910 - val_acc: 0.8932\n",
      "Epoch 89/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3237 - acc: 0.8777 - val_loss: 0.2957 - val_acc: 0.8912\n",
      "Epoch 90/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3217 - acc: 0.8780 - val_loss: 0.2956 - val_acc: 0.8912\n",
      "Epoch 91/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3194 - acc: 0.8786 - val_loss: 0.3095 - val_acc: 0.8854\n",
      "Epoch 92/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3199 - acc: 0.8785 - val_loss: 0.2992 - val_acc: 0.8906\n",
      "Epoch 93/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3192 - acc: 0.8794 - val_loss: 0.2889 - val_acc: 0.8934\n",
      "Epoch 94/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3180 - acc: 0.8795 - val_loss: 0.3011 - val_acc: 0.8885\n",
      "Epoch 95/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3158 - acc: 0.8811 - val_loss: 0.2896 - val_acc: 0.8948\n",
      "Epoch 96/100\n",
      "280371/280371 [==============================] - 134s 479us/step - loss: 0.3150 - acc: 0.8804 - val_loss: 0.2832 - val_acc: 0.8963\n",
      "Epoch 97/100\n",
      "280371/280371 [==============================] - 135s 481us/step - loss: 0.3145 - acc: 0.8821 - val_loss: 0.2799 - val_acc: 0.8975\n",
      "Epoch 98/100\n",
      "280371/280371 [==============================] - 135s 480us/step - loss: 0.3135 - acc: 0.8814 - val_loss: 0.2837 - val_acc: 0.8954\n",
      "Epoch 99/100\n",
      "280371/280371 [==============================] - 135s 481us/step - loss: 0.3112 - acc: 0.8825 - val_loss: 0.2895 - val_acc: 0.8942\n",
      "Epoch 100/100\n",
      "280371/280371 [==============================] - 134s 480us/step - loss: 0.3101 - acc: 0.8831 - val_loss: 0.2892 - val_acc: 0.8941\n",
      "[2 1 2 0 2 1 2 0 2 2 2 2 2 1 2 1 1 2 0 1 0 2 2 1 1 1 2 1 2 1 2 1 0 2 0 2 2\n",
      " 1 0 2 0 1 1 1 2 1 0 2 0 2 1 1 1 1 1 2 1 2 1 1 2 1 2 2 2 1 2 1 2 0 2 1 2 0\n",
      " 2 2 2 1 1 1 0 1 2 0 1 1 2 1 0 2 2 1 2 2 2 1 0 2 2 0 2 2 2 2 2 1 2 2 2 0 0\n",
      " 2 2 0 1 1 1 1 1 0 1 0 2 2 2 0 2 2 1 1 0 0 2 2 1 2 2 2 2 0 2 1 2 2 2 0 2 1\n",
      " 2 2 1 2 2 1 1 1 1 0 1 2 1 2 2 2 2 2 0 2 0 1 0 1 1 2 2 2 0 2 2 1 1 1 1 2 2\n",
      " 0 0 1 1 1 0 1 2 2 2 1 1 2 2 0 1 2 1 2 0 2 2 2 0 0 0 2 0 2 2 0 0 2 1 2 0 2\n",
      " 0 1 2 1 1 2 2 0 1 2 1 1 2 2 2 1 2 1 2 2 2 2 1 1 1 2 1 2 0 0 1 0 2 1 2 0 1\n",
      " 0 2 1 1 0 1 1 0 2 1 2 2 0 2 2 2 2 1 2 1 2 0 0 1 1 1 1 2 0 0 2 2 1 1 2 2 1\n",
      " 1 2 0 0 0 1 1 2 0 2 2 1 1 2 1 1 1 2 1 0 0 1 2 2 1 2 2 0 1 1 1 2 2 1 1 1 1\n",
      " 2 0 1 2 1 0 1 1 1 1 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 1 2 0 0 0 2 2 0 1 1 1 1\n",
      " 2 1 1 0 0 0 1 1 0 0 2 2 2 1 0 1 1 1 0 1 1 2 2 2 0 2 1 0 1 1 1 0 1 2 2 0 0\n",
      " 0 2 2 0 1 2 2 1 2 1 2 2 1 0 1 1 2 0 2 0 2 0 0 1 1 0 2 1 1 2 1 1 0 0 0 0 1\n",
      " 0 1 1 2 1 1 0 1 0 0 0 2 1 1 0 1 1 1 2 2 1 1 1 1 2 1 1 1 2 2 2 1 0 2 1 0 2\n",
      " 2 0 2 1 2 2 1 0 1 1 0 0 2 2 1 2 1 2 1 1 1 1 2 1 0 2 2 2 2 0 2 1 0 0 1 0 1\n",
      " 0 0 2 1 0 2 0 0 2 2 1 2 1 1 2 1 1 1 1 2 2 2 2 1 2 1 0 1 0 2 0 1 1 1 1 2 2\n",
      " 1 2 2 1 2 1 2 1 0 2 1 2 1 2 0 2 1 0 0 2 1 2 2 1 0 2 2 1 2 0 2 2 2 2 1 2 1\n",
      " 2 2 1 2 0 0 1 1 1 0 2 2 0 2 0 0 2 1 2 2 2 1 2 1 1 0 2 2 1 2 1 1 2 2 1 1 2\n",
      " 0 1 2 2 0 2 0 1 2 1 2 2 2 1 2 2 2 0 1 1 2 1 2 2 1 2 2 1 2 0 1 1 2 2 2 2 1\n",
      " 2 1 1 1 1 1 1 1 0 2 1 0 1 1 2 2 1 1 1 2 2 2 0 2 1 0 2 1 1 1 2 2 1 0 2 0 1\n",
      " 0 2 2 0 2 1 1 2 0 2 2 1 2 1 1 2 2 1 1 1 2 2 0 0 2 2 0 2 0 1 1 2 1 2 2 2 1\n",
      " 1 2 2 0 2 1 2 2 1 2 1 1 0 2 1 1 2 2 0 1 1 1 2 0 2 1 0 2 2 2 1 2 2 2 1 1 0\n",
      " 2 1 1 2 2 2 1 0 1 1 1 1 0 2 0 2 1 2 1 1 2 0 0 2 1 0 2 2 2 2 1 1 2 2 0 1 2\n",
      " 1 1 1 2 1 2 2 2 1 1 2 2 1 0 0 2 2 1 1 1 0 2 1 2 1 2 2 2 2 2 1 2 1 2 2 0 2\n",
      " 2 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 2 1 1 0 0 1 0 1 2 1 1 1 0 2 2 2 2 2 2 2 0\n",
      " 2 2 1 2 2 0 2 0 0 1 2 2 1 1 1 1 1 2 2 2 2 1 1 0 2 2 1 1 1 2 1 0 1 1 1 2 1\n",
      " 1 1 1 0 2 2 0 1 1 1 1 1 1 1 2 1 2 1 2 0 2 1 0 2 1 1 0 0 1 2 2 0 2 1 0 2 0\n",
      " 1 1 2 2 1 2 2 1 0 0 1 0 2 2 0 1 2 2 0 0 2 0 2 1 2 2 2 2 1 2 2 1 1 1 2 1 1]\n",
      "acc: 87.09%\n",
      "[0.3418666096301647, 0.8708708709901994]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NAME = \"German_noun-2Lstm1(60,128)-ep100-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.LSTM(60, input_shape=(X.shape[1:]), activation='relu', return_sequences=True))\n",
    "model.add(layers.Dropout(DROP_OUT))\n",
    "model.add(layers.LSTM(128, activation='relu'))\n",
    "model.add(layers.Dense(60, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X[1000:], Y[1000:], epochs=100, validation_split=0.25, callbacks=[tensorboard])\n",
    "\n",
    "prediction = model.predict_classes(X[:999])\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "print(prediction)\n",
    "\n",
    "scores = model.evaluate(X[:999], Y[:999], verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "print(scores)\n",
    "\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 0 2 1 2 0 2 2 2 2 2 1 2 1 1 2 0 1 0 2 2 1 1 1 2 1 2 1 2 1 0 2 0 2 2\n",
      " 1 0 2 0 1 1 1 2 1 0 2 0 2 1 1 1 1 1 2 1 2 1 1 2 1 2 2 2 1 2 1 2 0 2 1 2 0\n",
      " 2 2 2 1 1 1 0 1 2 0 1 1 2 1 0 2 2 1 2 2 2 1 0 2 2 0 2 2 2 2 2 1 2 2 2 0 0\n",
      " 2 2 0 1 1 1 1 1 0 1 0 2 2 2 0 2 2 1 1 0 0 2 2 1 2 2 2 2 0 2 1 2 2 2 0 2 1\n",
      " 2 2 1 2 2 1 1 1 1 0 1 2 1 2 2 2 2 2 0 2 0 1 0 1 1 2 2 2 0 2 2 1 1 1 1 2 2\n",
      " 0 0 1 1 1 0 1 2 2 2 1 1 2 2 0 1 2 1 2 0 2 2 2 0 0 0 2 0 2 2 0 0 2 1 2 0 2\n",
      " 0 1 2 1 1 2 2 0 1 2 1 1 2 2 2 1 2 1 2 2 2 2 1 1 1 2 1 2 0 0 1 0 2 1 2 0 1\n",
      " 0 2 1 1 0 1 1 0 2 1 2 2 0 2 2 2 2 1 2 1 2 0 0 1 1 1 1 2 0 0 2 2 1 1 2 2 1\n",
      " 1 2 0 0 0 1 1 2 0 2 2 1 1 2 1 1 1 2 1 0 0 1 2 2 1 2 2 0 1 1 1 2 2 1 1 1 1\n",
      " 2 0 1 2 1 0 1 1 1 1 1 1 2 1 2 1 1 2 2 2 1 2 2 1 1 1 2 0 0 0 2 2 0 1 1 1 1\n",
      " 2 1 1 0 0 0 1 1 0 0 2 2 2 1 0 1 1 1 0 1 1 2 2 2 0 2 1 0 1 1 1 0 1 2 2 0 0\n",
      " 0 2 2 0 1 2 2 1 2 1 2 2 1 0 1 1 2 0 2 0 2 0 0 1 1 0 2 1 1 2 1 1 0 0 0 0 1\n",
      " 0 1 1 2 1 1 0 1 0 0 0 2 1 1 0 1 1 1 2 2 1 1 1 1 2 1 1 1 2 2 2 1 0 2 1 0 2\n",
      " 2 0 2 1 2 2 1 0 1 1 0 0 2 2 1 2 1 2 1 1 1 1 2 1 0 2 2 2 2 0 2 1 0 0 1 0 1\n",
      " 0 0 2 1 0 2 0 0 2 2 1 2 1 1 2 1 1 1 1 2 2 2 2 1 2 1 0 1 0 2 0 1 1 1 1 2 2\n",
      " 1 2 2 1 2 1 2 1 0 2 1 2 1 2 0 2 1 0 0 2 1 2 2 1 0 2 2 1 2 0 2 2 2 2 1 2 1\n",
      " 2 2 1 2 0 0 1 1 1 0 2 2 0 2 0 0 2 1 2 2 2 1 2 1 1 0 2 2 1 2 1 1 2 2 1 1 2\n",
      " 0 1 2 2 0 2 0 1 2 1 2 2 2 1 2 2 2 0 1 1 2 1 2 2 1 2 2 1 2 0 1 1 2 2 2 2 1\n",
      " 2 1 1 1 1 1 1 1 0 2 1 0 1 1 2 2 1 1 1 2 2 2 0 2 1 0 2 1 1 1 2 2 1 0 2 0 1\n",
      " 0 2 2 0 2 1 1 2 0 2 2 1 2 1 1 2 2 1 1 1 2 2 0 0 2 2 0 2 0 1 1 2 1 2 2 2 1\n",
      " 1 2 2 0 2 1 2 2 1 2 1 1 0 2 1 1 2 2 0 1 1 1 2 0 2 1 0 2 2 2 1 2 2 2 1 1 0\n",
      " 2 1 1 2 2 2 1 0 1 1 1 1 0 2 0 2 1 2 1 1 2 0 0 2 1 0 2 2 2 2 1 1 2 2 0 1 2\n",
      " 1 1 1 2 1 2 2 2 1 1 2 2 1 0 0 2 2 1 1 1 0 2 1 2 1 2 2 2 2 2 1 2 1 2 2 0 2\n",
      " 2 1 2 2 1 2 1 2 1 2 1 2 1 2 2 2 2 1 1 0 0 1 0 1 2 1 1 1 0 2 2 2 2 2 2 2 0\n",
      " 2 2 1 2 2 0 2 0 0 1 2 2 1 1 1 1 1 2 2 2 2 1 1 0 2 2 1 1 1 2 1 0 1 1 1 2 1\n",
      " 1 1 1 0 2 2 0 1 1 1 1 1 1 1 2 1 2 1 2 0 2 1 0 2 1 1 0 0 1 2 2 0 2 1 0 2 0\n",
      " 1 1 2 2 1 2 2 1 0 0 1 0 2 2 0 1 2 2 0 0 2 0 2 1 2 2 2 2 1 2 2 1 1 1 2 1 1]\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "answer = [list(i).index(1) for i in Y[:1000]]\n",
    "score = 0\n",
    "for i in range(len(answer)):\n",
    "    if answer[i] == prediction[i]:\n",
    "        score += 1\n",
    "        pass\n",
    "    pass\n",
    "print(score)\n",
    "print(len(answer))\n",
    "result = 100 * score/len(answer)\n",
    "print(\"{}%\".format(round(result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
